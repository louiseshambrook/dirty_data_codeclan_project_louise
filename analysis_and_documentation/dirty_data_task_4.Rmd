---
title: "R Notebook"
output: html_notebook
---

NOTE TO MYSELF - WHEN I PICK UP ON TUESDAY - MOVE NOTES OVER FROM HERE to R SCRIPT

# Dirty Data - Louise Shambrook
## 26/11/2021

### - Required libraries
```{r}
library(readr)
library(readxl)
library(dplyr)
library(here)
library(janitor)
library(stringr)
library(tidyverse)
#calling libraries
```

```{r}
names(candy_2015)
```

## Points to include in final report:
- A brief introduction to the dataset
- A list of any assumptions you have made
- The steps you took to clean the data (you don’t need to write out in detail every step, but a combination of commented code chunks with surrounding overall explanations would be great).
- The answers to the questions presented in the task brief
- Any other interesting analyses or conclusions you come across.

# Final report (draft)

### Brief Introduction to the dataset
In 2006, David Ng and Ben Cohen began to rank candy based on their location
in geological strata, for trick or treating purposes. This has developed over
the years into a "not quite social science legit survey". As of 2019, this has 
become a way of measuring "net feelies" when trick or treating, for a wide range
of candies, which critically includes items such as hugs, glow sticks and bread.

Source: https://boingboing.net/author/davidng2

### Brief introductions to assumptions
- I intially assumed the dataset was complete, i.e. that the columns were correct
(should be there).
- As I began to dig in to it and opened it in excel, I learned that some of
these could be dropped.
- I then over-corrected and tried to drop too many.
- I then began to research the background of the dataset, and found that only
some of these would need to be dropped.
- I assume that many of the NA's can be dropped/changed without causing many problems.
- I assume that respondents will generally only be from the US and Canada.
- I assume that age will only be given in whole numbers.
- That the "random" columns at the end, were indeed random, however upon further
research and reading, I learned that these are indicators for charactor and that
this has an impact on the ratings. I have then begun to think about how I can 
change my data analysis to reflect this, as the time constraints of the project
means that realistically means I will not be able to include all of them.
Source: https://boingboing.net/2015/10/31/the-candy-hierarchy-2015-your.html
Table 1B. 

### Steps to clean the data
- Changing names of columns
- Changing timestamp of 2015 and 2016
- Changing column type of age

## Analysis

What is the total number of candy ratings given across the three years.
(Number of candy ratings, not the number of raters. Don’t count missing values)
```{r}
group_by
summarise(across(count))
```

What was the average age of people who are going out trick or treating?
```{r}
filter(going_out = yes)
group_by(age)
summarise(mean(age))
```

What was the average age of people who are not going trick or treating?
```{r}
filter(going_out = no)
group_by(age)
summarise(mean(age))
```

For each of joy, despair and meh, which candy bar received the most of these ratings?
```{r}

```

How many people rated Starburst as despair?
```{r}

```

For the next three questions, count despair as -1, joy as +1, and meh as 0.
What was the most popular candy bar by this rating system for each gender in
the dataset ?
```{r}
filter(f)
group_by(across(all(joy)))
summarise(sum(n))

```

What was the most popular candy bar in each year?
```{r}

```

What was the most popular candy bar by this rating for people in US, Canada,
UK, and all other countries?
```{r}

```

Any other interesting analyses or conclusions you come across.
```{r}
# Not my analysis, but if I have time, I would like to replicate it:
# ://boingboing.net/2015/10/31/the-candy-hierarchy-2015-your.html
# Table 1.B

# EXTENSION
# Step 7. For the "please leave"/"please List" columns, create a coding matrix,
# code the data.
# Step 8. Mints - change all non-numeric data to numeric.
# Step 9. Betty/Ver - Change all ?? to NA.
# Step 10. "Check all that apply" - split columns.
# Step 11. Add NA's to all the "random" columns in the blanks.
```


```{r}
# 2015 CLEANING  --------------------------------------------------------------
clean_2015 <- clean_names(candy_2015)

clean_2015 <- clean_2015 %>%
  rename(age = how_old_are_you,
         going_out = are_you_going_actually_going_trick_or_treating_yourself,
         year = timestamp,
         hersheys_kissables= hershey_s_kissables,
         hersheys_milk_chocolate = hershey_s_milk_chocolate,
         remarks_or_comments = please_leave_any_remarks_or_comments_regarding_your_choices,
         items_not_included_joy = please_list_any_items_not_included_above_that_give_you_joy,
         items_not_included_despair = please_list_any_items_not_included_above_that_give_you_despair
  )



clean_2015 <- clean_2015 %>%
  relocate(necco_wafers, .after = york_peppermint_patties)

clean_2015$year <- 2015

clean_2015$age[clean_2015$age == "45, but the 8-year-old Huntress and
                 bediapered Unicorn give me political cover and social
                 respectability.  However, I WILL eat more than they do
                 combined."] <- 45
clean_2015$age[clean_2015$age == "37 (I'm taking a child)"] <- 37
clean_2015$age[clean_2015$age == "Good Lord!  I'm 43!"] <- 43
clean_2015$age[clean_2015$age == "46:"] <- 46
clean_2015$age[clean_2015$age == "40. Deal with it. "] <- 40
clean_2015$age[clean_2015$age == "37,"] <- 37
clean_2015$age[clean_2015$age == "50 (despair)"] <- 50
clean_2015$age[clean_2015$age == "27^"] <- 27
clean_2015$age[clean_2015$age == "50, taking a 13 year old."] <- 50
clean_2015$age[clean_2015$age == "42 - I'm taking my kid"] <- 42
clean_2015$age[clean_2015$age == "42 - I'm taking my kid"] <- 42
clean_2015$age[clean_2015$age == "50t"] <- 50                 

# with this, I need to think about assertive programming and adding that in

clean_2015 <- clean_2015 %>%
  transform(age = as.numeric(age))

clean_2015 <- clean_2015 %>%
  add_column(gender = NA, .after = "going_out") %>%
  add_column(country = NA, .after = "gender") %>%
  add_column(state = NA, .after = "country")

# 2016 CLEANING ---------------------------------------------------------------

clean_2016 <- clean_names(candy_2016)

clean_2016 <- clean_2016 %>%
  rename(age = how_old_are_you,
         going_out = are_you_going_actually_going_trick_or_treating_yourself,
         year = timestamp,
         gender = your_gender,
         country = which_country_do_you_live_in,
         state = which_state_province_county_do_you_live_in,
         hersheys_milk_chocolate = hershey_s_milk_chocolate,
  )

clean_2016 <- clean_2016 %>%
  transform(age = as.numeric(age))

clean_2016$year <- 2016

clean_2016 %>%
  filter(country == "United States of America")

clean_2016 <- clean_2016 %>%
  relocate(age, .after = year)


# Change all versions of USA to USA, and similar for other countries.

# Remove incorrect strings. 

# Clean state column, i.e. ensure all strings are correct.

# Change all USA and canadian states to same format, e.g. TN, USA


# 2017 Cleaning --------------------------------------------------------------
clean_2017 <- clean_names(candy_2017)
# cleaning column names using clean_names from janitor package
clean_2017 <- clean_2017 %>%
  rename(going_out = q1_going_out,
         gender = q2_gender,
          age = q3_age,
          country = q4_country,
          state = q5_state_province_county_etc)
clean_2017 <- clean_2017 %>%
  rename(year = internal_id)

# Need to do an across or something to remove q6 from 7-109.
# Worst case; Ill hardcode it

# clean_2017 %>%
#   mutate(across(.cols, str_replace, "q", ""))

clean_2017 <- clean_2017 %>%
  relocate(age, .after = year)

clean_2017$internal_id <- 2017
# reassigning the internal_id column to 2017

# Cleaning the age column
# There are 2 answers which indicate a specific answer, e.g. "40. Deal with it".
# There are 5 which reference a vague answer, e.g. "50's". It is not
# reasonable to assume their answer - if there is time, I will go back and
# replace these with "vague" (or similar). Then there are the outright "invalid"
# answers, e.g. "old enough" which do not reference an age. These are NA.

clean_2017$age[clean_2017$age == "sixty-nine"] <- 69
clean_2017$age[clean_2017$age == "46 Halloweens"] <- 46

clean_2017 <- clean_2017 %>%
  transform(age = as.numeric(age))

replacing q6 - how to replace q6 in dplyr - extract columnm change and reassign

# Clean country names; ensure all countries are capitalised.

# Change all versions of USA to USA, and similar for other countries.

# Remove incorrect strings. 

# Clean state column, i.e. ensure all strings are correct.

# Change all USA and canadian states to same format, e.g. TN, USA
```


```{r}
#cleaning the USA

clean_2016 %>%
  filter(country != "USA")
#me testing for the regex

# strings to look for
# "uSA", "united states", "US", "usa", "United States of America",
#             "United States", "U.S.A.", "Murica", "USA!", "USA (I think but it's 
#             an election year so who can really tell)"


# Work in progress

usa_pattern <- "[wrlyutoceaAnisbISUk]."

clean_2016 %>%
  mutate(country = str_replace(country, "[wrlyutoceaAnisbISUk].", "USA"))



# pattern <- "[A-Z][a-z]+ [0-9]+(th|rd|st|nd), [0-9]{4}"
# whole_text %>%
#   str_extract(pattern)


```

